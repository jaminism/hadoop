하둡 개인 공부용 기록

**출처 : [빅데이터 전문가의 하둡 관리](https://book.naver.com/bookdb/book_detail.nhn?bid=14134329) (샘 R.emphasized text 알라파티 저 | 안진섭 역 | 성안당)**




# 빅데이터 플랫폼
**하둡에서 각 처리 단계를 담당하는 소프트웨어 컴포넌트를 모듈이라 칭함.**

### 1. 수집 모듈
    - 플럼
        클라우데라에서 개발. 
        서버에 Agent를 심어두고 이벤트 발생 시 데이터 전송

    - 카프카
        링크드인에서 개발.
        퍼블리셔와 컨슈머 형태로 동작하고 여러 대의 서버에 브로커 라는 프로세스를 띄워 프로듀서라는 프로세스들이 브로커에 데이터 전달.
    - 스쿱
        아파치에서 개발.  
        RDBMS와 연동이 목적. 최근에는 플럼 카프카도 RDBMS 연동 가능.
        
### 2. 데이터 저장 및 처리 모듈
    - 하둡
        HDFS, MapReduce 제공
    - HBase
        HDFS를 저장소로 사용하는 컬럼 기반 NoSQL DB
    - 카산드라
        페북에서 개발.
        HBase와 같은 컬럼 기반 NoSQL 데이터베이스로 분류
    - 레디스(Redis)
        메모리를 이용한 키, 값 형태의 저상소
    - 피그
        피그라틴이라는 스크립트 인어로 작성하여 맵리듀스 실행
    - 하이브
        SQL 과 비슷한 스크립트 언어를 제공하여 맵리듀스 실행
    - 스파크
        하둡과 유사한 클러스터 기반의 분산 처리 기능을 제공하는 오픈소스 프레임워크.
        하둡에 비해 반복적인 데이터를 처리하는 데 뛰어난 성능을 보인다(인메모리 기반)
        
### 3. 데이터 분석 및 기타 소프트웨어 모듈
    - R
        데이터에 대한 수치 처리 및 그래픽 처리 기능을 제공.
    - 클라우데라, 호튼웍스
        CDH, HDP 으로 배포되는 하둡 에코시스템을 구성하는 플랫폼.
    - 엘라스틱 서치
        루씬을 기반으로 개발된 RESTful 분산 검색 엔진.
        주로 JSON 형태로 데이터를 저장하고 검색, 집계, 통계, 머신러닝 등의 영역이 활용.
    
    
### - 기타 정보
    . 암바리(Ambari : 클러스터 관리),
    . 아브로 (Avro; 데이터 직렬화).
    . 카산드라 (Cassandra; 멀티마스터 데이터베이스),
    . 척와 (Chukwa : 데이터 수집),
    . 에이치베이스 (HBase : 분산 데이터베이스)
    . 하이브(Hive ; 데이터 창고,
    . 머하웃(Mahout : ML 및 데이터 마이닝),
    . 피그 (Pig : 실행 프레임워크).
    . 스파크 (Spark : 검퓨트 엔진).
    . 테즈 (Tez : 맵리듀스를 대체할 데이터 플로우 프로그래밍 프레임워크).
    . 주키퍼 (ZooKeeper 코디네이션 서비스)
    . 아파치 스톰(Storm ; 스트림 처리),
    . 카프카 (Kafka , 메시지 전송).
    . 부가가치를 제공하는 아마존 EMR(Elastic Map Reduce),
    . 클리우데라 (Cloudera),
    . 호튼웍스 (Hortonworks),
    . 마이크로스프트 (에이치디인사이트(HDInsight).
    . 맵알 (MapR),
    . SAP 알티스케일 (Altiscale) 도 있다.

    . 아파치 스쿱 = 관계형 데이터베이스의 데이터를 HDFS로 옮기는 컴포넌트
    . 아파치 들룸 = 많은 양의 스트리밍 데이터를 수집, 종합하고 다양한 소스로부터 HDFS와 같은 데이터 저장소로 이동하는 시스템.
    . 아파치 카프가 = 링크드인에서 개발, 병렬 로딩이 가능하고 실시간 데이터 소비를 클러스터로 분할해줌으로써 오프라인과 온라인 스트리밍 데이터 처리를 결합할 수 있다.
    . 이외에도 엘라스틱써치, Logstash, Kibana 있다.



## 버전별 특징 
### 1) version 1
    - 병렬처리 (맵리듀스) 
		잡트래커와 태스크트래커가 담당 
	- 분산저장(HDFS) 
		네임노드와 데이터노드가 담당
	- 클러스터 자원관리와 라이프사이클 관리를 모두 함에 병목현상 발생하여 문제가 됨
	
### 2) version 2
	- 클러스터 관리 
		리소스 매니저, 노드 매니저 
	- 작업 관리 
		애플리케이션 마스터, 컨테이너
	- YARN 아키텍처의 작업처리 단위는 컨테이너.
	- 프로세스
		작업 제출 > AM 생성 > AM이 RM에 지원 요청 > RM이 컨테이너를 AM 에 할당 > 컨테이너가 할당 되면 생성 되고 작업 완료 후 종료
### 3) version 3
	- 이레이져 코딩 도입으로 HDFS 데이터 저장 효율성 증가
		> 잡트레커 = RM+AM 이 역할 수행 
		> 테스트크래커 = 노드매니저(워커노드 관리) 

 
 
## 다중 처리 엔진들
- 배치 프로세싱 - 맵리듀스, 하이브/피그, 테즈
-   인터랙티브 SQL - 테즈
-   온라인 데이터베이스 - HBase
-   스트리밍 - 스톰, 스파크, Sanza | 인메모리 - 스파크
-   그래프 프로세싱 - 지라프, 스파크 그러프엑스 . HPC MPI - OpenMPI
-   대용량 검색 - 솔라 


## HDFS
- HDFS (Hadoop Distributed File System) 는 범용 하드웨어에서 동작하고, 장애 복구성을 가지는 분산 파일 시스템을 목표. 
- 단일 실패 지점 (SPOF)이 되기 때문에 네임노드 관리가 중요 

- 특징  
 블록 단위 저장 블록 복제를 이용한 장애 복구 읽기 중심 . 
 데이터 지역성 (데이터가 있는곳에서 알고리즘 처리 > 네트워크 이동 비용 감소)

1.  구조 
	1-1.  네임노드
	- 메타데이터 관리 
		- 파일이름, 크기, 생성시간, 권한 등의 정보 
		- Fsimage(네임스페이스, 블록 정보) 
		- Edits (파일 관련 로그, 메모리 저장하다가 주기적 생성) 

## 잡 스케줄링 
- 우지 
	- 제어 의존성이 비순환 방향 그래프(DAG) 로 정렬되는 워크플로 스케줄링 시스템. 
	- 하둡의 잡은 대개 상호의존적이라 크론으로는 우지를 대체할 수 없다. 

## 하둡 데이터 보안
- 기본적으로 하둡은 롤 기반 액세스나 객체 수준의 액세스를 설정할 수 없다. 
- 그래서 인증받지 않은 사용자들이 노드 에 접근해 클러스터를 공격할 수도 있다. 
- 커버로스 
		- 사용자 인증 부분의 보안 관련 오픈소스 인증 메커니즘


## 하둡 필요조건
- 확장성 (Scalability)
- 장애허용 (Fault tolerance)
- 회복력 (Recoverability)  
---
- HDFS 에서 파일생성이나 삭제가 발생하면 메타데이터가 변경되고 **fsImage** 에 기록이 반영된다. 그리고 매 시간(기본값)마다 보조 네임노드가 fsImage 파일을 합치는 작업을 한다.

-   클라이언트는 데이터노드에 직접 접근할 수 없어 어떤 데이터노드가 호스팅 하는지는 알수 없지만, 네임노드에 접속하여 파일 블록 Number나 데이터위치(데이터노드)를 알수 있다. 즉, 네임노드는 클라이언트가 데이터를 기록할 수 있는 데이터노드 목록을 보내주는 일을 함으로써 클라이언트가 어디에 기록할지 결정할 수 있다.
- 초기 메타데이터는 fsImage에 저장되며 파일의 생성, 삭제 등으로 변화할 때 트랜잭션 로그가 기록된다. 세컨더리 네임노드는 주기적으로 fsImage와 로그파일을 통합한다. 이 작업이 완료되면 네임노드는 변경내용을 기록한 파일을 삭제한다. 
- 얀은 분산 애플리케이션을 관리하기 위한 관리 프레임워크. 얀은 하둡 프로세싱 레이어로 리소스 매니저와 잡 스케줄러를 포함한다. 이는 다른 분산 프로세싱 프레임워크인 맵리듀 스, 스파크, 테즈를 포함한 하둡 환경에서 작동한다. 
- 얀은 컨테이너를 사용해 애플리케이션을 실행한다. 리소스매니저는 컨테이너를 각 애플리게이션에 스케줄링하고, 노드매니저는 컨테이너의 라이프사이클을 관리한다.  
- 얀은 다양한 실행 엔진들로 동작하는 다양한 환경을 관리함 -> 배치 프로세싱, 인터랙티브 환경, 실시간 프로세싱을 위한 엔진이 동작하면 HDFS에 접근 가능 
- 얀은 어플리케이션 작업량을 관리하고 모니터링 함 
- 맵, 리듀스 태스크가 완료되면 컨테이너는 소멸되고 남은 다른 태스크가 있을 때 새로운 컨테이너가 생성된다. 
- 리소스매니저는 클러스터 당 하나만 존재한다. 역할은 다음과 같다.
  -   모든 얀 애플리케이션의 시작을 위한 처리
  -   잡 스케줄링과 실행 관리
  -   모든 데이터노드의 리소스 할당
  -   데이터노드를 관리하기 위해 노드매니저의 하트비트 관리 
- 노드매니저의 기능
  - 하트비트와 컨테이너 상태 알림을 통해 리소스매니저와 정보를 주고 받는다.
  - 애플리케이션 컨테이너의 라이프 사이클을 관리
  - 데이터노드의 상태 추적
  - 컨테이너 리소스 사용량 정보를 관리 
- 애플리게이션 마스터 
  - 각각의 애플리케이션에는 전용 애플리케이션 마스터가 존재
  -   태스크 스케줄링과 실행 관리
  -  애플리케이션 태스크를 위해 로컬 리소스 할당

## 맵리듀스 프레임워크
   ### 1. 맵리듀스 모델
   - 맵 단계 : 입력 파일을 병렬 처리 방식으로 처리해 중간 결과로 출력한다.
   - 리듀스 단계 · 모든 관련 레코드를 통합시키는 단계
   - 대표 클래스 :
     -  입력 파일을 읽어 들이고 입력 레코드를 키/값 쌍으로 변경하는 클래스
     - 맵퍼 클래스
     - 리듀서 클래스
     - 리듀서 클래스에서 생성한 키/값 쌍을 변경해 최종 출력 레코드로 변형하는 클래스
            
-  수행 과정 :
	-  맵 프로세스는 커다란 파일을 여러 개의 칭크로 쪼갠다. 
       각 청크들은 동시에 다수의 맵퍼 프로세스들로 처리되며, 처리된 결과가 정렬돼 파티션을 이룬다.
    -  리듀스 태스크들이 정렬된 청크들 각각을 가져와서 프로세싱하고 최종 결과 파일을 만든다.

### 2. 맵리듀스 동작 방식
- 각 맵퍼는 HDFS 의 파일 한부분(split)을 처리하며, 한 부분의 크기는 블록사이즈와 일치한다.
 - 하둡은 한번에 하나의 레코드를 맵퍼로 보내며 키/값을 가진다.
 - 맵퍼는 한번에 하나의 레코드만 처리하고 중간 결과를 디스크에 기록한다.
- 리듀서는 맵퍼가 만들어 낸 중간 키들을 이용해 결과를 종합한다.
- 동일한 중간 키와 관련된 모든 값들은 동일한 리듀서로 보내진다.
- 리듀서는 HDFS에 최종 결과를 기록한다.
###  3. 데이터 압축
- 맵리듀스의 처리량을 높이려면 디스크 및 네트워크 I/O를 줄여야 한다.
- 이를 위해 입력파일을 압축하거나 맵퍼의 결과를 압축한다.

### 4. 맵리듀스 잡 프로세싱
- 다수의 맵 프로세스들은 동시에 시작된다
- HDFS 디렉토리로부터 입력 스플릿(전체 입력 데이더의 일부)을 읽어들이고 데이터를 처리해 중간 키/값 쌍을 만든다.
- 리듀서 프로세스는 동일한 키를 갖는 모든 키/값 쌍을 처리하고 다음 단계 수행
- 리듀서 프로세스는 키/값 쌍으로 된 최종 결과를 출력 디렉토리에 저장
 
      각 맵리듀스 테스크는 입력 스클릿 하나를 처리한다.

- 클라이언트가 클러스터에 잡을 서밋하기 전에 입력 스플릿 크기가 계산된다. 
- 블록 사이즈가 대부분 스플릿 사이즈로 사용된다.
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTExMjU3NzU3NzMsLTIxMzU5ODIzMDIsLT
E2OTM2MDM4ODcsLTEzMjc3NDAzMTcsLTE0Mzc3MzY2MTMsLTE5
OTE5ODM2MTRdfQ==
-->